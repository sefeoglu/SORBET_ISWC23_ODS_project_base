(base) sefika@AP-NBK-VXD2H src % python train.py
[INFO - 2023-12-21 14:09:35] - Using gpu: False
[INFO - 2023-12-21 14:09:35] - CUDA version: None
[INFO - 2023-12-21 14:09:36] - Pairwise training started
[INFO - 2023-12-21 14:09:36] - pretrained: sentence-transformers/all-MiniLM-L6-v2
[INFO - 2023-12-21 14:09:36] - candidate_selector: none
[INFO - 2023-12-21 14:09:36] - matcher: greedy with thresholds [0.6, 0.65, 0.7, 0.725, 0.75, 0.775, 0.8, 0.85]
[INFO - 2023-12-21 14:09:36] - Test size: 1.0
[INFO - 2023-12-21 14:09:36] - Extra track: None
[INFO - 2023-12-21 14:09:36] - iir: 0.8
[INFO - 2023-12-21 14:09:36] - inter_soft_r: 0.0
[INFO - 2023-12-21 14:09:36] - intra_soft_r: 0.0
[INFO - 2023-12-21 14:09:36] - negative_sampling_strategy: ontologic_relation
[INFO - 2023-12-21 14:09:36] - no_hard_negative_samples: False
[INFO - 2023-12-21 14:09:36] - epoch_over_alignments: False
[INFO - 2023-12-21 14:09:36] - A: 5
[INFO - 2023-12-21 14:09:36] - batch_size: 32
[INFO - 2023-12-21 14:09:36] - n_alignments_per_batch: 4
Some weights of the model checkpoint at sentence-transformers/all-MiniLM-L6-v2 were not used when initializing BertModel: ['pooler.dense.bias', 'pooler.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[INFO - 2023-12-21 14:09:36] - Started training with run_id: {self.run_id}
* Owlready2 * WARNING: ObjectProperty http://openconf#has_Reccommendation belongs to more than one entity types: [owl.ObjectProperty, owl.DeprecatedProperty]; I'm trying to fix it...
* Owlready2 * WARNING: ObjectProperty http://openconf#has_Reccommendation belongs to more than one entity types: [owl.ObjectProperty, owl.DeprecatedProperty]; I'm trying to fix it...
[INFO - 2023-12-21 14:09:38] - Reference train alignments size: 0
[INFO - 2023-12-21 14:09:38] - train alignments size: 759
[INFO - 2023-12-21 14:09:38] - Metrics for track: conference
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
        - Avoid using `tokenizers` before the fork if possible
        - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
[INFO - 2023-12-21 14:10:00] - #### Metrics ####
[INFO - 2023-12-21 14:10:00] - 
                0       1       2       3       4       5       6       7       8
Threshold  0.6000  0.6500  0.7000  0.7250  0.7500  0.7750  0.8000  0.8250  0.8500
Precision  0.5569  0.6325  0.6917  0.7225  0.7477  0.7629  0.8103  0.8609  0.8819
Recall     0.7375  0.6911  0.6409  0.6332  0.6178  0.5714  0.5444  0.5019  0.4324
F1         0.6346  0.6605  0.6653  0.6749  0.6765  0.6534  0.6513  0.6341  0.5803
[INFO - 2023-12-21 14:10:00] - Hits@1    : 0.8223938223938224
[INFO - 2023-12-21 14:10:00] - Hits@3    : 0.9073359073359073
[INFO - 2023-12-21 14:10:00] - Hits@5    : 0.9382239382239382
[INFO - 2023-12-21 14:10:00] - Hits@10    : 0.9613899613899614
[INFO - 2023-12-21 14:10:27] - Eval time: 49.48889183998108
[INFO - 2023-12-21 14:10:27] - ################################################# ---------- EPOCH 0 ---------- #################################################
[INFO - 2023-12-21 14:13:08] - Epoch: 0 time:(total= 160.30426907539368, pytorch=158.96478080749512), losses: (fcosine: 0.0600246787071228)
[INFO - 2023-12-21 14:13:08] - cosine: 0.0600246787071228
[INFO - 2023-12-21 14:13:08] - Metrics for track: conference
[INFO - 2023-12-21 14:13:31] - #### Metrics ####
[INFO - 2023-12-21 14:13:31] - 
                0       1       2       3       4       5       6       7       8
Threshold  0.6000  0.6500  0.7000  0.7250  0.7500  0.7750  0.8000  0.8250  0.8500
Precision  0.3461  0.4118  0.4974  0.5441  0.5833  0.6268  0.6958  0.7260  0.7870
Recall     0.8031  0.7838  0.7529  0.7143  0.7027  0.6873  0.6448  0.5830  0.5135
F1         0.4837  0.5399  0.5991  0.6177  0.6375  0.6556  0.6693  0.6467  0.6215
[INFO - 2023-12-21 14:13:31] - Hits@1    : 0.8301158301158301
[INFO - 2023-12-21 14:13:31] - Hits@3    : 0.9266409266409267
[INFO - 2023-12-21 14:13:31] - Hits@5    : 0.9498069498069498
[INFO - 2023-12-21 14:13:31] - Hits@10    : 0.9691119691119691
[INFO - 2023-12-21 14:13:58] - Eval time: 49.91217613220215
[INFO - 2023-12-21 14:13:58] - ################################################# ---------- EPOCH 1 ---------- #################################################
